{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDBReview.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAYWwFz2w823",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpomfmjfxEZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load imdb data and split it into training and testing datasets\n",
        "vocabulary_size=5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euGd1qap4SgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inspecting data\n",
        "#print(X_train)\n",
        "#print(y_train)\n",
        "print(\"Review:\",X_train[0])\n",
        "print(\"Label:\",y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJpeDbJN4QKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decode the sentences to see the reviews as text\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "#print(word_index)\n",
        "reverse_word_index = dict(\n",
        "[(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "decoded_review = ' '.join(\n",
        "[reverse_word_index.get(i - 3, '?') for i in X_train[0]])\n",
        "\n",
        "print(X_train[0])\n",
        "print(decoded_review)\n",
        "\n",
        "decoded_review = ' '.join(\n",
        "[reverse_word_index.get(i - 3, '?') for i in X_train[2]])\n",
        "\n",
        "print(X_train[2])\n",
        "print(decoded_review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5PRozExI2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pad the sequences\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "print(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nihx4VYOxnn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize the model\n",
        "embedding_size=32\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(tf.keras.layers.LSTM(100))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkfEEjIMxyY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnjhhUvW6des",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#divide X_train in train and validation datasets\n",
        "batch_size = 64\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train_partial, y_train_partial = X_train[batch_size:], y_train[batch_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCC2aIAw79l2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    DESIRED_ACC = 0.9\n",
        "    if(logs.get('val_accuracy')>=DESIRED_ACC):\n",
        "      print(\"\\nStopping training as validation accuracy is reached to %.2f!\" % DESIRED_ACC )\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q69jhZiFyhuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "num_epochs = 5\n",
        "history=model.fit(X_train_partial, y_train_partial, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs, callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQJvCwN63v9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test the model and print test accuracy score\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLxbU0094hjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#try your model with your reviews\n",
        "\n",
        "#sentence1: This film is the worst film I have ever seen\n",
        "#sentence2: Excellent! superb film, worth watching\n",
        "sentence = input()\n",
        "\n",
        "#get the word_index from imdb dataset\n",
        "word_index = imdb.get_word_index()\n",
        "#print(word_index)\n",
        "\n",
        "#Get the tokens for the words of the entered sentence\n",
        "X_tmp = [word_index[word]+3 for word in sentence.split() if word in word_index]\n",
        "\n",
        "#pad the sentence to make it of equal length\n",
        "X_new = pad_sequences([X_tmp], maxlen=max_words)\n",
        "\n",
        "#predict sentiment for the entered review\n",
        "y_pred=model.predict_classes(X_new)\n",
        "#print(X_new)\n",
        "\n",
        "if y_pred[0]==1:\n",
        "    print(\"Positive\") #1 means positive\n",
        "else:\n",
        "    print(\"Negative\") #0 means negative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCSicj5Q6bya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('IMDBReviewModel.h5')\n",
        "model_json = model.to_json()\n",
        "with open('IMDBReviewModel.json', \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "json_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}